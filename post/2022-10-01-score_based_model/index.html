<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Score-based Generative Model | Jiaxiang's Blogs</title>
<meta name=keywords content><meta name=description content="The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement."><meta name=author content="Me"><link rel=canonical href=https://jiaxiangc.github.io/post/2022-10-01-score_based_model/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jiaxiangc.github.io/post/2022-10-01-score_based_model/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Score-based Generative Model"><meta property="og:description" content="The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement."><meta property="og:type" content="article"><meta property="og:url" content="https://jiaxiangc.github.io/post/2022-10-01-score_based_model/"><meta property="og:image" content="https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-10-15T11:30:03+00:00"><meta property="article:modified_time" content="2022-10-15T11:30:03+00:00"><meta property="og:site_name" content="Homepage Test"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Score-based Generative Model"><meta name=twitter:description content="The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://jiaxiangc.github.io/post/"},{"@type":"ListItem","position":2,"name":"Score-based Generative Model","item":"https://jiaxiangc.github.io/post/2022-10-01-score_based_model/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Score-based Generative Model","name":"Score-based Generative Model","description":"The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement.","keywords":[],"articleBody":"The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement. DDPM, the Denoising Diffusion Probabilistic Model, was introduced by Ho et al. in 2020, and it is distinguished from SMLD by its noise addition approach. SDEs refer to the Stochastic Differential Equations used by Dr. Song in his 2021 paper to theoretically evolve the discrete noise addition processes of SMLD and DDPM into a continuous form, thereby unifying the sampling equations of SMLD and DDPM with SDEs. With this brief introduction complete, let us now move on to the section on mathematical reasoning.\nScore-Based Generative Modeling Score Function The objective of generative tasks is to fit the model parameters to approximate the true data probability distribution \\( p(x) \\). This probability distribution is typically modeled as \\( p_\\theta(x) = \\frac{e^{-f_\\theta(x)}}{Z_\\theta} \\), where \\( f_\\theta(x) \\in \\mathbb{R} \\) and \\( Z_\\theta \\) is the normalization term that ensures \\( p_\\theta(x) \\) falls within the probability range. The above distribution is generally referred to as an unnormalized probabilistic model. Our goal is to maximize \\( \\log p_\\theta(x) \\) through the log-likelihood method. However, since \\( Z_\\theta \\) is an unknown quantity, we cannot derive \\( \\log p_\\theta(x) \\), and thus we cannot optimize the model parameters.\nTo address the issue of the incalculable \\( Z_\\theta \\), the authors propose the score function, which is defined by the following formula:\n$$ s_\\theta(x) = \\nabla_x \\log p_\\theta(x) = - \\nabla_x f_\\theta(x) - \\nabla_x \\log Z_\\theta = -\\nabla_x f_\\theta(x) $$ We can observe that the score function \\( s_\\theta(x) \\) is independent of \\( Z_\\theta \\), thus circumventing the problem of the unknown \\( Z_\\theta \\). With the known \\( s_\\theta(x) \\), we can construct a loss function to approximate \\( s(x) \\), thereby accomplishing the generative task.\nScore Matching Score matching, which includes denoising score matching and sliced score matching, is a technique used in generative modeling. Since we will be consistently referring to denoising score matching in the following context, we will use this term. With this, we have our loss function defined as:\n$$ \\mathcal{L} = \\mathbb{E}_{p(x)} \\left[ \\left\\| \\nabla_x \\log p(x) - s_\\theta(x) \\right\\|^2 \\right] $$ If we knew the true distribution \\( p(x) \\), we could optimize this loss function. However, since we do not, the authors introduced score matching, a method that minimizes the loss function without knowing \\( p(x) \\), making \\( \\mathcal{L} \\) equivalent to another form:\n$$ \\mathcal{L} = \\mathbb{E}_{p(x)} \\left[ \\left\\| s_\\theta(x) \\right\\|^2 + 2 \\text{tr}(\\nabla_x s_\\theta(x)) \\right] $$ To briefly explain the derivation, we expand the expectation, break down the quadratic form, and obtain:\n$$ \\mathcal{L} = \\int p(x) \\left[ \\left\\| \\nabla_x \\log p(x) \\right\\|^2 + \\left\\| s_\\theta(x) \\right\\|^2 - 2(\\nabla_x \\log p(x))^T s_\\theta(x) \\right] dx $$ This expression contains three terms. The first term does not involve \\( \\theta \\) and can be ignored. The second term is \\( \\int p(x) \\left\\| s_\\theta(x) \\right\\|^2 dx \\), and the third term, after manipulation, becomes \\( 2 \\int p(x) \\text{tr}(\\nabla_x s_\\theta(x)) dx \\) after integration by parts.\nLooking back at the loss function, \\( \\nabla_x s_\\theta(x) \\) represents the Jacobian matrix of \\( s_\\theta(x) \\), which is computationally complex. Can we avoid computing the Jacobian matrix? The authors cleverly used denoising score matching, which perturbs the data \\( x \\) with a fixed noise distribution to obtain \\( q_\\sigma(\\tilde{x}|x) \\). The loss function then becomes:\n$$ \\mathcal{L} = \\mathbb{E}_{p(x)} \\left[ \\left\\| \\nabla_{\\tilde{x}} \\log q_\\sigma(\\tilde{x}|x) - s_\\theta(\\tilde{x}) \\right\\|^2 \\right] $$ Now, since \\( q_\\sigma(\\tilde{x}|x) \\) is known, we can directly optimize to obtain \\( s_{\\theta^*}(x) = \\nabla_x \\log q_\\sigma(x) \\); clearly, when the added noise is sufficiently small, we can assume \\( s_{\\theta^*}(x) = \\nabla_x \\log q_\\sigma(x) \\approx \\nabla_x \\log p_{\\text{data}}(x) \\).\nWith this, we have completed the optimization of the score-based model, which can help us accomplish a series of generative tasks. So, how should we use it to enable random noise to be restored to an image close to the true data distribution?\nLangevin Dynamics Sample To recover an image close to the true data distribution from random noise, one can employ Langevin dynamics sampling. This sampling method can transform random noise, which follows any distribution, into an image. Langevin dynamics sampling can perform sampling from a probability density function \\( p(x) \\) based solely on the score function \\( \\nabla_x \\log p(x) \\). Given a fixed step size \\( \\epsilon \u003e 0 \\) and an initial noise \\( \\tilde{x} \\sim \\pi(x) \\), where \\( \\pi \\) can be any distribution, the formula for Langevin dynamics sampling is as follows:\n$$ \\tilde{x}_t = \\tilde{x}_{t-1} + \\frac{\\epsilon}{2} \\nabla_x \\log p(\\tilde{x}_{t-1}) + \\sqrt{\\epsilon} z_t $$ Here, \\( z_t \\sim \\mathcal{N}(0, I) \\). As \\( \\epsilon \\rightarrow 0 \\) and \\( T \\rightarrow \\infty \\), the distribution of \\( \\tilde{x}_T \\) equals \\( p(x) \\). It is not difficult to see that the above formula only requires \\( \\nabla_x \\log p(x) \\). Therefore, to generate samples close to the distribution \\( p_{\\text{data}}(x) \\), we can first train a score model \\( s_\\theta(x) \\approx \\nabla_x \\log p_{\\text{data}}(x) \\) .\nWith this, we have obtained a model composed of score matching and Langevin dynamics sampling, hence called the SMLD (Score Matching Langevin Dynamics) model. However, this model actually has significant issues. Let’s now examine what these problems are and how the authors addressed them.\nNoise Conditional Score Networks Let’s first examine the loss function of the SMLD model, where the issue arises:\n$$ \\mathcal{L} = \\mathbb{E}_{p(x)} \\left[ \\left\\| \\nabla_x \\log p(x) - s_\\theta(x) \\right\\|^2 \\right] = \\int p(x) \\left\\| \\nabla_x \\log p(x) - s_\\theta(x) \\right\\|^2 dx $$ It is evident that \\( p(x) \\) acts as a weight on the L2 term. Consequently, when \\( p(x) \\) reaches areas of low density, the L2 term loses its effectiveness as a loss function. In these regions, the estimated score model \\( s_\\theta(x) \\) becomes inaccurate, as illustrated in the figure below. The predicted scores closely match the actual data scores in high-density areas, but they are inaccurate in low-density areas. If this issue is not addressed, it becomes impossible to generate samples that conform to the true distribution.\nTo address this problem, the authors proposed improvements to the score matching approach. One such improvement is to use a different weighting scheme that does not depend on the density of \\( p(x) \\) in areas where the density is low. This can be achieved by employing alternative loss functions that penalize deviations of the score estimates more uniformly across the sample space, regardless of the local density of \\( p(x) \\). By doing so, the model can learn to accurately represent the score function even in low-density regions, thus improving the generative capabilities of the model and enabling it to produce samples that better reflect the true data distribution.\nTo address the issue, the authors introduced Noise Conditional Score Networks (NCSN), which expands the high-density area of the data distribution by adding noise perturbations to the data. By superimposing Gaussian noise on the data distribution, the mean remains unchanged while the variance increases, effectively enlarging the area of the high-density region. This enlargement allows for more accurate estimation of the score function in a broader range of areas.\nOnce the approach of adding noise is established, we must consider whether to add noise once or multiple times, and whether to add a small or large amount of noise. Clearly, if the noise perturbation is small, it will not significantly affect the data distribution; conversely, if the noise perturbation is large, it will alter the original data distribution. Therefore, the authors propose a compromise: to add noise multiple times, starting small and increasing in intensity. We define a sequence \\(\\{ \\sigma_i \\}_{i=1}^L\\), with \\(\\sigma_1 \u003c \\sigma_2 \u003c ... \u003c \\sigma_L\\), representing noise intensities from low to high. This allows us to define the distribution of the data after noise perturbation as follows:\n$$ x + \\sigma_i z \\sim p_{\\sigma_i}(x) = \\int p(y) \\mathcal{N}(x|y, \\sigma_i^2I)dy $$ We then estimate a series of score functions for the noise-perturbed distributions and sum them to obtain:\n$$ \\mathcal{L} = \\sum_{i=1}^L \\sigma_i^2 \\ \\mathbb{E}_{p(x)} \\left[ \\left\\| \\nabla_{\\tilde{x}} \\log p_{\\sigma_i}(x) - s_\\theta(x) \\right\\|^2 \\right] $$ For the training of NCSN, using denoising score matching, we define the noise distribution as \\( q_\\sigma(\\tilde{x}|x) = \\mathcal{N}(\\tilde{x}|x,\\sigma^2I) \\), hence the score function \\( \\nabla_{\\tilde{x}} \\log q_{\\sigma}(\\tilde{x}|x) = -(\\tilde{x}-x)/\\sigma^2 \\). Given a \\( \\sigma \\), the loss function for NCSN can be written as:\n$$ l(\\theta;\\sigma) := \\frac{1}{2} \\mathbb{E}_{p_{\\text{data}}(x)} \\mathbb{E}_{\\tilde{x} \\sim \\mathcal{N}(x, \\sigma^2I)} \\left[ \\left\\| s_\\theta(\\tilde{x}, \\sigma) + \\frac{\\tilde{x}-x}{\\sigma^2} \\right\\|^2 \\right] $$ With the loss function for a single noise level, we can derive the formula for all noise levels:\n$$ \\mathcal{L}(\\theta;\\{\\sigma_i \\}_{i=1}^L) := \\frac{1}{L} \\sum_{i=1}^L \\lambda(\\sigma_i)l(\\theta; \\sigma_i) $$ Given that \\( s_{\\theta^*}(x,\\sigma_i) = \\nabla_x \\log q_{\\sigma_i}(x) \\), the optimization of the loss function is completed. Note that the input to the score model is not only \\( x \\) but also the noise intensity \\( \\sigma_i \\). It is important to clarify that \\( \\lambda(\\sigma_i) \\) is a coefficient function that depends on \\( \\sigma_i \\), and there are various ways to choose it. The authors wish for the different noise loss functions \\( \\lambda(\\sigma) l(\\theta; \\sigma) \\) to be on the same scale. Through “experimental observation,” it was found that \\( \\lVert s_\\theta(x, \\sigma) \\rVert \\propto 1/\\sigma \\). Therefore, the authors set \\( \\lambda(\\sigma) = \\sigma^2 \\) to ensure that different \\( \\lambda(\\sigma) l(\\theta; \\sigma) \\) are on the same scale, making the loss function independent of the noise level.\nFor NCSN sampling, instead of direct Langevin dynamics sampling, annealed Langevin dynamics sampling is used. This method, as shown in the figure, performs Langevin dynamics sampling on data distributions with different noise intensities from large to small, using the sampling result of \\( L \\) as the initial value for the \\( L-1 \\) sampling. Finally, when \\( \\sigma_1 \\approx 0 \\), \\( q_{\\sigma_1}(x) \\) approaches the true data distribution \\( p_{\\text{data}}(x) \\).\nFrom Algorithm 1, it can be seen that the sampling step size \\( \\alpha_i \\) is proportional to the noise intensity; the larger the noise intensity, the larger the sampling step size. Each sampling can obtain \\( \\tilde{x}_T \\), which will serve as the initial value \\( \\tilde{x}_0 \\) for the \\( L-1 \\) moment. The logic shown in this algorithm is in the order from 1 to \\( L \\) (here \\( \\sigma_1 \u003e \\sigma_L \\), from Dr. Song’s thesis), while my description is the process from \\( L \\) to 1 ( \\( \\sigma_1 \u003c \\sigma_L \\), from Dr. Song’s blog), it’s just a difference in notation; in reality, both are processes from high noise to low noise, so don’t get confused.\nConsider why the above sampling method can solve the initial problem of inaccuracy in low-density areas; we can assume that a good sample is drawn from \\( q_{\\sigma_L}(x) \\), which is likely to come from the high-density area of \\( q_{\\sigma_L}(x) \\). Given the small difference between \\( q_{\\sigma_L}(x) \\) and \\( q_{\\sigma_{L-1}}(x) \\), this sample is also very likely to be in the high-density area of \\( q_{\\sigma_{L-1}}(x) \\). Since the score estimation performs better in high-density areas, this sample can be used as the initial value for \\( q_{\\sigma_{L-1}}(x) \\). At this point, some may ask, aren’t you trying to solve the inaccuracy in low-density areas? Why are you always improving the accuracy in high-density areas? Note that the accuracy in the high-density area of \\( q_{\\sigma_L}(x) \\) implies that some low-density areas of \\( q_{\\sigma_{L-1}}(x) \\) are also accurate, doesn’t it? This method ensures the accuracy of low-density areas while also achieving continuous optimization of score estimation in high-density areas.\nWith this, the content of Dr. Song’s 2019 paper has been introduced. It is not difficult to see that the difference between SMLD (NCSN) and DDPM lies in the different noise addition methods and sampling methods. SMLD (NCSN) involves adding multiple noises to the original image and then restoring the image based on the annealed Langevin sampling method; DDPM involves iteratively adding multiple noises to the original image and then restoring the image based on the Markov chain property to deduce the sampling formula.\nScore-Based Models with SDEs SDEs Dr. Yang Song’s 2021 paper is based on Stochastic Differential Equations (SDEs) for image diffusion and sampling, an approach that expresses the finite discrete sampling process as an infinite continuous one. The SDE-based method can be seen as a general sampling approach for diffusion models, unifying SMLD and DDPM.\nBefore delving into the application of SDEs, let’s review the optimization objectives of SMLD and DDPM. The optimization objective for SMLD is:\n$$ \\boldsymbol{\\theta}^{*} = \\underset{\\boldsymbol{\\theta}}{\\arg \\min } \\sum_{i=1}^{N} \\sigma_{i}^{2} \\mathbb{E}_{p_{\\text {data }}(\\mathbf{x})} \\mathbb{E}_{p_{\\sigma_{i}}(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})}\\left[\\left\\|\\mathbf{s}_{\\boldsymbol{\\theta}}\\left(\\tilde{\\mathbf{x}}, \\sigma_{i}\\right)-\\nabla_{\\tilde{\\mathbf{x}}} \\log p_{\\sigma_{i}}(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})\\right\\|_{2}^{2}\\right] $$ The sampling method is the Langevin dynamics sampling formula: $$ x_i^m = x_i^{m-1} + \\epsilon_i s_{\\theta^*}(x_i^{m-1}, \\sigma_i) + \\sqrt{2 \\epsilon_i}z_i^m, \\ m =1,2,...,M $$ where \\( i \\) denotes the corresponding noise level, and \\( m \\) represents the current moment of sampling the image.\nThe optimization objective for DDPM can also be written in a similar form to SMLD:\n$$ \\boldsymbol{\\theta}^{*} = \\underset{\\boldsymbol{\\theta}}{\\arg \\min } \\sum_{i=1}^{N} (1-\\alpha_i) \\mathbb{E}_{p_{\\text {data }}(\\mathbf{x})} \\mathbb{E}_{p_{\\alpha_{i}}(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})}\\left[\\left\\|\\mathbf{s}_{\\boldsymbol{\\theta}}\\left(\\tilde{\\mathbf{x}}, \\sigma_{i}\\right)-\\nabla_{\\tilde{\\mathbf{x}}} \\log p_{\\alpha_{i}}(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})\\right\\|_{2}^{2}\\right] $$ The sampling method follows the reverse Markov chain: $$ x_{i-1} = \\frac{1}{\\sqrt{1-\\beta_i}}(x_i + \\beta_i s_{\\theta^*}(x_i, i)) + \\sqrt{\\beta_i}z_i, \\ i=N,N-1,...,1 $$ The optimization of these two algorithms can be written in the same form, which gives us reason to believe that there may be a unified expression to represent both SMLD and DDPM. So, what is this specific form of expression? Let’s continue to explore.\nFrom discrete to continuous, the forward SDEs perturb the data. When the noise level tends to infinity, we can consider a continuously increasing noise perturbing the original data distribution. In this case, the noise addition process (diffusion process) is a time-continuous stochastic process. The authors propose a concise way to express such stochastic processes, namely SDEs. Why can SDEs be used to represent this? This is because many stochastic processes (especially diffusion processes) are solutions to SDEs. The general formula for SDEs is as follows:\n$$ dx = f(x,t)dt + g(t)d \\bf{w} $$ Here, \\( f: \\mathbb{R}^d \\rightarrow \\mathbb{R}^d \\), called the drift coefficient, \\( g(t) \\in \\mathbb{R} \\), called the diffusion coefficient, \\( \\bf{w} \\) represents a standard Brownian motion, and \\( d \\bf{w} \\) can be seen as infinitesimally small Gaussian noise. At this point, \\( x(t) \\) represents the random variable perturbed by noise at time \\( t \\), and \\( p_t(x) \\) represents the marginal probability density function of \\( x(t) \\). Comparing with the finite noise addition, we can consider \\( p_t(x) \\) similar to \\( p_{\\sigma_i}(x) \\), so \\( p_0(x) \\) can be considered the original data distribution. When \\( T \\rightarrow \\infty \\), we can consider \\( p_T(x) \\) close to the prior distribution of random noise \\( \\pi(x) \\), which is equivalent to adding the maximum noise perturbation to the data.\nSDEs can be artificially designed, similar to how we add noise in NCSN, with the following SDE design:\n$$ dx = e^t d \\bf{w} $$ This is equivalent to perturbing the data with a Gaussian noise with a mean of 0 and an exponentially increasing variance. (Here, it is stated that \\( d\\bf{w} \\) is an infinitesimal Gaussian distribution). So far, we have designed a noise addition method similar to NCSN based on SDEs, so we have reason to believe that we can express NCSN and DDPM using SDEs.\nReverse SDEs The reverse SDEs for sample generation were proposed by B.D. Anderson in 1982, stating that every SDE has a corresponding reverse SDE equation, as follows:\n$$ dx = [f(x,t) - g^2(t) \\nabla_x \\log p_t(x)]dt + g(t)d\\bf{w} $$ Here, \\(dt\\) is a negative infinitesimally small time step, and \\(t\\) is the process from \\(T \\rightarrow 0\\). To solve the reverse SDE, we need to determine the score function \\(\\nabla_x \\log p_t(x)\\).\nSimilar to the NCSN loss function, we can still implement SDE-based score estimation based on the score model and score matching method, replacing the noise in the discrete process at the \\(i\\)th time with the noise at time \\(t\\), with the formula as follows:\n$$ \\mathcal{L}=\\mathbb{E}_{t \\in \\mathcal{U}(0,T)} \\mathbb{E}_{p_t(x)} [\\lambda(t) \\lVert \\nabla_x \\log p_t(x) - s_\\theta(x,t) \\rVert^2_2] $$ Here, to ensure that the loss is of the same order at different \\(t\\) times, let \\(\\lambda(t) \\propto 1/ \\mathbb{E} \\lVert \\log p(x(t)|x(0)) \\rVert^2_2\\). After optimizing the score model \\(s_\\theta(x,t)\\), substitute it into the reverse SDE:\n$$ dx = [f(x,t) - g^2(t)s_\\theta(x,t)]dt + g(t)d\\bf{w} $$ After calculating the specific expression of the reverse SDE, we need to consider how to solve the reverse SDE.\nSolving the reverse SDE. We can use numerical methods to solve the reverse SDE, among which the simplest numerical method is the Euler-Maruyama method. This method describes the reverse SDE with finite time steps and infinitesimal Gaussian noise. Specifically, it initializes \\(t=T\\), \\(\\nabla_t \\approx 0\\) (negative time difference), and iterates the following process until \\(t \\approx 0\\):\n$$ \\begin{align*} \\Delta x \u0026 \\leftarrow [f(x,t) - g^2(t)s_\\theta(x,t)] \\Delta t + g(t) \\sqrt{|\\Delta t|}z_t \\\\ x \u0026 \\leftarrow x + \\Delta x \\\\ t \u0026 \\leftarrow t + \\Delta t \\end{align*} $$ Of course, in addition to this, the author also mentioned other numerical methods, such as the Milstein method and the stochastic Runge-Kutta method. Since the author did not use these methods in the end, they are not elaborated here. Interested friends can study the corresponding papers.\nThe author proposed a method similar to the Euler-Maruyama method but more suitable for this reverse SDE, which is a method more suitable for this framework, called the predictor-corrector (PC) sampling method.\nThe PC sampling method can be viewed from two stages. The first stage is prediction, that is, to solve the \\(x_i\\) of the previous moment by any numerical method. However, due to the existence of errors at this time, the results are inaccurate, so the second stage of correction is needed to adjust the obtained results for \\(M\\) steps. This stage mainly uses the sampling method in the score model for correction, such as Langevin MCMC. As for the specific sampling formula, we will not discuss it for now, because our goal is not to use a specific SDE to represent SMLD or DDPM. Next, I will introduce how to unify the above two models with SDEs.\nSDEs Unify Diffusion Models For SMLD, by subtracting the noise addition formula at moments \\( \\sigma_i \\) and \\( \\sigma_{i-1} \\), we can obtain the following noise addition method:\n$$ x_i = x_{i-1} + \\sqrt{\\sigma_i^2 - \\sigma_{i-1}^2} z_{i-1}, \\ z_{i-1} \\sim \\mathcal{N}(0,I) $$ As the number of noise additions approaches infinity, we can derive:\n$$ \\begin{align*} x(t + \\Delta t) - x(t) \u0026= \\sqrt{\\frac{d\\sigma^2(t)}{dt}} \\sqrt{\\Delta t} z(t) \\\\ dx \u0026= \\sqrt{\\frac{d\\sigma^2(t)}{dt}} dw \\end{align*} $$ For DDPM, the noise addition method is:\n$$ x_i = \\sqrt{1-\\beta_i}x_{i-1} + \\sqrt{\\beta_i}z_{i-1}, \\ z_{i-1} \\sim \\mathcal{N}(0, I) $$ As the number of noise additions approaches infinity, we can derive:\n$$ dx = -\\frac{1}{2} \\beta(t)xdt + \\sqrt{\\beta(t)}dw $$ Since in the noise addition process, the noise in SMLD tends to infinity as \\( t \\rightarrow \\infty \\), its corresponding SDE is referred to as a Variance Exploding (VE) SDE. Conversely, the noise in DDPM tends to a boundary value as \\( t \\rightarrow \\infty \\), so its corresponding SDE is referred to as a Variance Preserving (VP) SDE.\nAfter determining the SDE representations for SMLD and DDPM, let’s revisit the specific expressions of the PC sampling in the two algorithms, as shown in Algorithm 2, 3.\nThe prediction phase can use any numerical method to solve the reverse SDE, while the correction phase uses the MCMC method based on the score model. In PC sampling, the predictor and corrector are used alternately. Specifically, the numerical method is used as the predictor, and the annealed Langevin dynamics sampling is used as the corrector.\nFrom SDEs to ODEs. For an SDE, we can express the SDE in an equivalent form based on the Fokker-Planck equation:\n$$ dx = [f(x,t)-\\frac{1}{2}(g^2(t)-\\sigma^2(t))\\nabla_x \\log p_t(x)]dt + \\sigma(t)d\\bf{w} $$ The two SDE formulations are equivalent, hence they share the same marginal probability distribution \\( p_t(x) \\). If we set \\( \\sigma(t) = 0 \\) in the SDE, we obtain an ordinary differential equation (ODE), commonly referred to as the Probability Flow ODE:\n$$ dx = [f(x,t)-\\frac{1}{2} g^2(t)\\nabla_x \\log p_t(x)]dt $$ The figure below illustrates the noise addition and sampling processes of SDEs and Probability Flow ODEs. It can be seen that the trajectory of the Probability Flow ODE is smooth, while the trajectory of the SDE is stochastic, but they share the same marginal distribution. Some may wonder why the Probability Flow ODE is mentioned suddenly, of course, it is because it has advantages over SDEs. For example, ODEs are easier to solve than SDEs, thus faster in sampling; ODEs discard random noise throughout the process, making the process deterministic, allowing for the calculation of probability density. However, ODEs also have disadvantages, such as not generating as well as SDEs.\nAdditionally, when \\( \\nabla_x \\log p_t(x) \\) is replaced by the approximated \\( s_\\theta(x,t) \\), the Probability Flow ODE becomes a special case of a Neural ODE. At the same time, the Probability Flow ODE is also an example of a continuous Flow model because the Probability Flow ODE transforms the data distribution into the prior noise distribution, and the process is reversible. Therefore, the Probability Flow ODE inherits the characteristics of Neural ODEs or continuous Flow models, such as accurate likelihood calculation. We can use numerical ODEs to calculate unknown data distributions from the prior distribution.\nReference [1] Yang Song, https://yang-song.net/blog/2021/score/.\n[2] Song, Y., \u0026 Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32.\n[3] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., \u0026 Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.\n","wordCount":"3734","inLanguage":"en","image":"https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-10-15T11:30:03Z","dateModified":"2022-10-15T11:30:03Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaxiangc.github.io/post/2022-10-01-score_based_model/"},"publisher":{"@type":"Organization","name":"Jiaxiang's Blogs","logo":{"@type":"ImageObject","url":"https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"]]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jiaxiangc.github.io/ accesskey=h title="Jiaxiang's Blogs (Alt + H)"><img src=https://jiaxiangc.github.io/apple-touch-icon.png alt aria-label=logo height=35>Jiaxiang's Blogs</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://jiaxiangc.github.io/post/ title=POSTS><span>POSTS</span></a></li><li><a href=https://jiaxiangc.github.io/tags/ title=TAGS><span>TAGS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jiaxiangc.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://jiaxiangc.github.io/post/>Posts</a></div><h1 class="post-title entry-hint-parent">Score-based Generative Model</h1><div class=post-meta><span title='2022-10-15 11:30:03 +0000 +0000'>October 15, 2022</span>&nbsp;·&nbsp;18 min&nbsp;·&nbsp;3734 words&nbsp;·&nbsp;Me</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ol><li><a href=#score-based-generative-modeling>Score-Based Generative Modeling</a><ol><li><a href=#score-function>Score Function</a></li><li><a href=#score-matching>Score Matching</a></li><li><a href=#langevin-dynamics-sample>Langevin Dynamics Sample</a></li><li><a href=#noise-conditional-score-networks>Noise Conditional Score Networks</a></li></ol></li><li><a href=#score-based-models-with-sdes>Score-Based Models with SDEs</a><ol><li><a href=#sdes>SDEs</a></li><li><a href=#reverse-sdes>Reverse SDEs</a></li><li><a href=#sdes-unify-diffusion-models>SDEs Unify Diffusion Models</a></li></ol></li><li><a href=#reference>Reference</a></li></ol></nav></div></details></div><div class=post-content><p>The content introduced in this article pertains to SMLD, NCSN, DDPM, and SDEs. Before we proceed with the main body of the article, I will first clarify the specific relationships among these concepts for the readers. The SMLD model, proposed by Dr. Song in his 2019 thesis, is a generative method primarily composed of score matching and Langevin dynamics sampling. Given that this method has certain limitations—details of which are presented in the mathematical reasoning section—the author introduced the NCSN method as an improvement. DDPM, the Denoising Diffusion Probabilistic Model, was introduced by Ho et al. in 2020, and it is distinguished from SMLD by its noise addition approach. SDEs refer to the Stochastic Differential Equations used by Dr. Song in his 2021 paper to theoretically evolve the discrete noise addition processes of SMLD and DDPM into a continuous form, thereby unifying the sampling equations of SMLD and DDPM with SDEs. With this brief introduction complete, let us now move on to the section on mathematical reasoning.</p><h2 id=score-based-generative-modeling>Score-Based Generative Modeling<a hidden class=anchor aria-hidden=true href=#score-based-generative-modeling>#</a></h2><h3 id=score-function>Score Function<a hidden class=anchor aria-hidden=true href=#score-function>#</a></h3><p>The objective of generative tasks is to fit the model parameters to approximate the true data probability distribution \( p(x) \). This probability distribution is typically modeled as \( p_\theta(x) = \frac{e^{-f_\theta(x)}}{Z_\theta} \), where \( f_\theta(x) \in \mathbb{R} \) and \( Z_\theta \) is the normalization term that ensures \( p_\theta(x) \) falls within the probability range. The above distribution is generally referred to as an <em>unnormalized probabilistic model</em>. Our goal is to maximize \( \log p_\theta(x) \) through the log-likelihood method. However, since \( Z_\theta \) is an unknown quantity, we cannot derive \( \log p_\theta(x) \), and thus we cannot optimize the model parameters.</p><p>To address the issue of the incalculable \( Z_\theta \), the authors propose the score function, which is defined by the following formula:</p>$$
s_\theta(x) = \nabla_x \log p_\theta(x) = - \nabla_x f_\theta(x) - \nabla_x \log Z_\theta = -\nabla_x f_\theta(x)
$$<p>We can observe that the score function \( s_\theta(x) \) is independent of \( Z_\theta \), thus circumventing the problem of the unknown \( Z_\theta \). With the known \( s_\theta(x) \), we can construct a loss function to approximate \( s(x) \), thereby accomplishing the generative task.</p><h3 id=score-matching>Score Matching<a hidden class=anchor aria-hidden=true href=#score-matching>#</a></h3><p>Score matching, which includes denoising score matching and sliced score matching, is a technique used in generative modeling. Since we will be consistently referring to denoising score matching in the following context, we will use this term. With this, we have our loss function defined as:</p>$$
\mathcal{L} = \mathbb{E}_{p(x)} \left[ \left\| \nabla_x \log p(x) - s_\theta(x) \right\|^2 \right]
$$<p>If we knew the true distribution \( p(x) \), we could optimize this loss function. However, since we do not, the authors introduced score matching, a method that minimizes the loss function without knowing \( p(x) \), making \( \mathcal{L} \) equivalent to another form:</p>$$
\mathcal{L} = \mathbb{E}_{p(x)} \left[ \left\| s_\theta(x) \right\|^2 + 2 \text{tr}(\nabla_x s_\theta(x)) \right]
$$<p>To briefly explain the derivation, we expand the expectation, break down the quadratic form, and obtain:</p>$$
\mathcal{L} = \int p(x) \left[ \left\| \nabla_x \log p(x) \right\|^2 + \left\| s_\theta(x) \right\|^2 - 2(\nabla_x \log p(x))^T s_\theta(x) \right] dx
$$<p>This expression contains three terms. The first term does not involve \( \theta \) and can be ignored. The second term is \( \int p(x) \left\| s_\theta(x) \right\|^2 dx \), and the third term, after manipulation, becomes \( 2 \int p(x) \text{tr}(\nabla_x s_\theta(x)) dx \) after integration by parts.</p><p>Looking back at the loss function, \( \nabla_x s_\theta(x) \) represents the Jacobian matrix of \( s_\theta(x) \), which is computationally complex. Can we avoid computing the Jacobian matrix? The authors cleverly used denoising score matching, which perturbs the data \( x \) with a fixed noise distribution to obtain \( q_\sigma(\tilde{x}|x) \). The loss function then becomes:</p>$$
\mathcal{L} = \mathbb{E}_{p(x)} \left[ \left\| \nabla_{\tilde{x}} \log q_\sigma(\tilde{x}|x) - s_\theta(\tilde{x}) \right\|^2 \right]
$$<p>Now, since \( q_\sigma(\tilde{x}|x) \) is known, we can directly optimize to obtain \( s_{\theta^*}(x) = \nabla_x \log q_\sigma(x) \); clearly, when the added noise is sufficiently small, we can assume \( s_{\theta^*}(x) = \nabla_x \log q_\sigma(x) \approx \nabla_x \log p_{\text{data}}(x) \).</p><p>With this, we have completed the optimization of the score-based model, which can help us accomplish a series of generative tasks. So, how should we use it to enable random noise to be restored to an image close to the true data distribution?</p><h3 id=langevin-dynamics-sample>Langevin Dynamics Sample<a hidden class=anchor aria-hidden=true href=#langevin-dynamics-sample>#</a></h3><p>To recover an image close to the true data distribution from random noise, one can employ Langevin dynamics sampling. This sampling method can transform random noise, which follows any distribution, into an image. Langevin dynamics sampling can perform sampling from a probability density function \( p(x) \) based solely on the score function \( \nabla_x \log p(x) \). Given a fixed step size \( \epsilon > 0 \) and an initial noise \( \tilde{x} \sim \pi(x) \), where \( \pi \) can be any distribution, the formula for Langevin dynamics sampling is as follows:</p>$$
\tilde{x}_t = \tilde{x}_{t-1} + \frac{\epsilon}{2} \nabla_x \log p(\tilde{x}_{t-1}) + \sqrt{\epsilon} z_t
$$<p>Here, \( z_t \sim \mathcal{N}(0, I) \). As \( \epsilon \rightarrow 0 \) and \( T \rightarrow \infty \), the distribution of \( \tilde{x}_T \) equals \( p(x) \). It is not difficult to see that the above formula only requires \( \nabla_x \log p(x) \). Therefore, to generate samples close to the distribution \( p_{\text{data}}(x) \), we can first train a score model \( s_\theta(x) \approx \nabla_x \log p_{\text{data}}(x) \) .</p><p>With this, we have obtained a model composed of score matching and Langevin dynamics sampling, hence called the SMLD (Score Matching Langevin Dynamics) model. However, this model actually has significant issues. Let&rsquo;s now examine what these problems are and how the authors addressed them.</p><h3 id=noise-conditional-score-networks>Noise Conditional Score Networks<a hidden class=anchor aria-hidden=true href=#noise-conditional-score-networks>#</a></h3><p>Let&rsquo;s first examine the loss function of the SMLD model, where the issue arises:</p>$$
\mathcal{L} = \mathbb{E}_{p(x)} \left[ \left\| \nabla_x \log p(x) - s_\theta(x) \right\|^2 \right] = \int p(x) \left\| \nabla_x \log p(x) - s_\theta(x) \right\|^2 dx
$$<p>It is evident that \( p(x) \) acts as a weight on the L2 term. Consequently, when \( p(x) \) reaches areas of low density, the L2 term loses its effectiveness as a loss function. In these regions, the estimated score model \( s_\theta(x) \) becomes inaccurate, as illustrated in the figure below. The predicted scores closely match the actual data scores in high-density areas, but they are inaccurate in low-density areas. If this issue is not addressed, it becomes impossible to generate samples that conform to the true distribution.</p><p>To address this problem, the authors proposed improvements to the score matching approach. One such improvement is to use a different weighting scheme that does not depend on the density of \( p(x) \) in areas where the density is low. This can be achieved by employing alternative loss functions that penalize deviations of the score estimates more uniformly across the sample space, regardless of the local density of \( p(x) \). By doing so, the model can learn to accurately represent the score function even in low-density regions, thus improving the generative capabilities of the model and enabling it to produce samples that better reflect the true data distribution.</p><p><img loading=lazy src=/images/2022-10-01-score_based_model/pitfalls.jpg alt></p><p>To address the issue, the authors introduced Noise Conditional Score Networks (NCSN), which expands the high-density area of the data distribution by adding noise perturbations to the data. By superimposing Gaussian noise on the data distribution, the mean remains unchanged while the variance increases, effectively enlarging the area of the high-density region. This enlargement allows for more accurate estimation of the score function in a broader range of areas.</p><p><img loading=lazy src=/images/2022-10-01-score_based_model/single_noise.jpg alt></p><p>Once the approach of adding noise is established, we must consider whether to add noise once or multiple times, and whether to add a small or large amount of noise. Clearly, if the noise perturbation is small, it will not significantly affect the data distribution; conversely, if the noise perturbation is large, it will alter the original data distribution. Therefore, the authors propose a compromise: to add noise multiple times, starting small and increasing in intensity. We define a sequence \(\{ \sigma_i \}_{i=1}^L\), with \(\sigma_1 < \sigma_2 < ... < \sigma_L\), representing noise intensities from low to high. This allows us to define the distribution of the data after noise perturbation as follows:</p>$$
x + \sigma_i z \sim p_{\sigma_i}(x) = \int p(y) \mathcal{N}(x|y, \sigma_i^2I)dy
$$<p>We then estimate a series of score functions for the noise-perturbed distributions and sum them to obtain:</p>$$
\mathcal{L} = \sum_{i=1}^L \sigma_i^2 \ \mathbb{E}_{p(x)} \left[ \left\| \nabla_{\tilde{x}} \log p_{\sigma_i}(x) - s_\theta(x) \right\|^2 \right]
$$<p>For the training of NCSN, using denoising score matching, we define the noise distribution as \( q_\sigma(\tilde{x}|x) = \mathcal{N}(\tilde{x}|x,\sigma^2I) \), hence the score function \( \nabla_{\tilde{x}} \log q_{\sigma}(\tilde{x}|x) = -(\tilde{x}-x)/\sigma^2 \). Given a \( \sigma \), the loss function for NCSN can be written as:</p>$$
l(\theta;\sigma) := \frac{1}{2} \mathbb{E}_{p_{\text{data}}(x)} \mathbb{E}_{\tilde{x} \sim \mathcal{N}(x, \sigma^2I)} \left[ \left\| s_\theta(\tilde{x}, \sigma) + \frac{\tilde{x}-x}{\sigma^2} \right\|^2 \right]
$$<p>With the loss function for a single noise level, we can derive the formula for all noise levels:</p>$$
\mathcal{L}(\theta;\{\sigma_i \}_{i=1}^L) := \frac{1}{L} \sum_{i=1}^L \lambda(\sigma_i)l(\theta; \sigma_i)
$$<p>Given that \( s_{\theta^*}(x,\sigma_i) = \nabla_x \log q_{\sigma_i}(x) \), the optimization of the loss function is completed. Note that the input to the score model is not only \( x \) but also the noise intensity \( \sigma_i \). It is important to clarify that \( \lambda(\sigma_i) \) is a coefficient function that depends on \( \sigma_i \), and there are various ways to choose it. The authors wish for the different noise loss functions \( \lambda(\sigma) l(\theta; \sigma) \) to be on the same scale. Through &ldquo;experimental observation,&rdquo; it was found that \( \lVert s_\theta(x, \sigma) \rVert \propto 1/\sigma \). Therefore, the authors set \( \lambda(\sigma) = \sigma^2 \) to ensure that different \( \lambda(\sigma) l(\theta; \sigma) \) are on the same scale, making the loss function independent of the noise level.</p><p>For NCSN sampling, instead of direct Langevin dynamics sampling, annealed Langevin dynamics sampling is used. This method, as shown in the figure, performs Langevin dynamics sampling on data distributions with different noise intensities from large to small, using the sampling result of \( L \) as the initial value for the \( L-1 \) sampling. Finally, when \( \sigma_1 \approx 0 \), \( q_{\sigma_1}(x) \) approaches the true data distribution \( p_{\text{data}}(x) \).</p><p>From <em>Algorithm 1</em>, it can be seen that the sampling step size \( \alpha_i \) is proportional to the noise intensity; the larger the noise intensity, the larger the sampling step size. Each sampling can obtain \( \tilde{x}_T \), which will serve as the initial value \( \tilde{x}_0 \) for the \( L-1 \) moment. The logic shown in this algorithm is in the order from 1 to \( L \) (here \( \sigma_1 > \sigma_L \), from Dr. Song&rsquo;s thesis), while my description is the process from \( L \) to 1 ( \( \sigma_1 < \sigma_L \), from Dr. Song&rsquo;s blog), it&rsquo;s just a difference in notation; in reality, both are processes from high noise to low noise, so don&rsquo;t get confused.</p><p><img loading=lazy src=/images/2022-10-01-score_based_model/ald.gif alt></p><p>Consider why the above sampling method can solve the initial problem of inaccuracy in low-density areas; we can assume that a good sample is drawn from \( q_{\sigma_L}(x) \), which is likely to come from the high-density area of \( q_{\sigma_L}(x) \). Given the small difference between \( q_{\sigma_L}(x) \) and \( q_{\sigma_{L-1}}(x) \), this sample is also very likely to be in the high-density area of \( q_{\sigma_{L-1}}(x) \). Since the score estimation performs better in high-density areas, this sample can be used as the initial value for \( q_{\sigma_{L-1}}(x) \). At this point, some may ask, aren&rsquo;t you trying to solve the inaccuracy in low-density areas? Why are you always improving the accuracy in high-density areas? Note that the accuracy in the high-density area of \( q_{\sigma_L}(x) \) implies that some low-density areas of \( q_{\sigma_{L-1}}(x) \) are also accurate, doesn&rsquo;t it? This method ensures the accuracy of low-density areas while also achieving continuous optimization of score estimation in high-density areas.</p><p>With this, the content of Dr. Song&rsquo;s 2019 paper has been introduced. It is not difficult to see that the difference between SMLD (NCSN) and DDPM lies in the different noise addition methods and sampling methods. SMLD (NCSN) involves adding multiple noises to the original image and then restoring the image based on the annealed Langevin sampling method; DDPM involves iteratively adding multiple noises to the original image and then restoring the image based on the Markov chain property to deduce the sampling formula.</p><h2 id=score-based-models-with-sdes>Score-Based Models with SDEs<a hidden class=anchor aria-hidden=true href=#score-based-models-with-sdes>#</a></h2><h3 id=sdes>SDEs<a hidden class=anchor aria-hidden=true href=#sdes>#</a></h3><p>Dr. Yang Song&rsquo;s 2021 paper is based on Stochastic Differential Equations (SDEs) for image diffusion and sampling, an approach that expresses the finite discrete sampling process as an infinite continuous one. The SDE-based method can be seen as a general sampling approach for diffusion models, unifying SMLD and DDPM.</p><p>Before delving into the application of SDEs, let&rsquo;s review the optimization objectives of SMLD and DDPM. The optimization objective for SMLD is:</p>$$
\boldsymbol{\theta}^{*} = \underset{\boldsymbol{\theta}}{\arg \min } \sum_{i=1}^{N} \sigma_{i}^{2} \mathbb{E}_{p_{\text {data }}(\mathbf{x})} \mathbb{E}_{p_{\sigma_{i}}(\tilde{\mathbf{x}} \mid \mathbf{x})}\left[\left\|\mathbf{s}_{\boldsymbol{\theta}}\left(\tilde{\mathbf{x}}, \sigma_{i}\right)-\nabla_{\tilde{\mathbf{x}}} \log p_{\sigma_{i}}(\tilde{\mathbf{x}} \mid \mathbf{x})\right\|_{2}^{2}\right]
$$<p>The sampling method is the Langevin dynamics sampling formula:</p>$$
x_i^m = x_i^{m-1} + \epsilon_i s_{\theta^*}(x_i^{m-1}, \sigma_i) + \sqrt{2 \epsilon_i}z_i^m, \ m =1,2,...,M
$$<p>where \( i \) denotes the corresponding noise level, and \( m \) represents the current moment of sampling the image.</p><p>The optimization objective for DDPM can also be written in a similar form to SMLD:</p>$$
\boldsymbol{\theta}^{*} = \underset{\boldsymbol{\theta}}{\arg \min } \sum_{i=1}^{N} (1-\alpha_i) \mathbb{E}_{p_{\text {data }}(\mathbf{x})} \mathbb{E}_{p_{\alpha_{i}}(\tilde{\mathbf{x}} \mid \mathbf{x})}\left[\left\|\mathbf{s}_{\boldsymbol{\theta}}\left(\tilde{\mathbf{x}}, \sigma_{i}\right)-\nabla_{\tilde{\mathbf{x}}} \log p_{\alpha_{i}}(\tilde{\mathbf{x}} \mid \mathbf{x})\right\|_{2}^{2}\right]
$$<p>The sampling method follows the reverse Markov chain:</p>$$
x_{i-1} = \frac{1}{\sqrt{1-\beta_i}}(x_i + \beta_i s_{\theta^*}(x_i, i)) + \sqrt{\beta_i}z_i, \ i=N,N-1,...,1
$$<p>The optimization of these two algorithms can be written in the same form, which gives us reason to believe that there may be a unified expression to represent both SMLD and DDPM. So, what is this specific form of expression? Let&rsquo;s continue to explore.</p><p>From discrete to continuous, the forward SDEs perturb the data. When the noise level tends to infinity, we can consider a continuously increasing noise perturbing the original data distribution. In this case, the noise addition process (diffusion process) is a time-continuous stochastic process. The authors propose a concise way to express such stochastic processes, namely SDEs. Why can SDEs be used to represent this? This is because many stochastic processes (especially diffusion processes) are solutions to SDEs. The general formula for SDEs is as follows:</p>$$
dx = f(x,t)dt + g(t)d \bf{w}
$$<p>Here, \( f: \mathbb{R}^d \rightarrow \mathbb{R}^d \), called the drift coefficient, \( g(t) \in \mathbb{R} \), called the diffusion coefficient, \( \bf{w} \) represents a standard Brownian motion, and \( d \bf{w} \) can be seen as infinitesimally small Gaussian noise. At this point, \( x(t) \) represents the random variable perturbed by noise at time \( t \), and \( p_t(x) \) represents the marginal probability density function of \( x(t) \). Comparing with the finite noise addition, we can consider \( p_t(x) \) similar to \( p_{\sigma_i}(x) \), so \( p_0(x) \) can be considered the original data distribution. When \( T \rightarrow \infty \), we can consider \( p_T(x) \) close to the prior distribution of random noise \( \pi(x) \), which is equivalent to adding the maximum noise perturbation to the data.</p><p>SDEs can be artificially designed, similar to how we add noise in NCSN, with the following SDE design:</p>$$
dx = e^t d \bf{w}
$$<p>This is equivalent to perturbing the data with a Gaussian noise with a mean of 0 and an exponentially increasing variance. (Here, it is stated that \( d\bf{w} \) is an infinitesimal Gaussian distribution). So far, we have designed a noise addition method similar to NCSN based on SDEs, so we have reason to believe that we can express NCSN and DDPM using SDEs.</p><p><img loading=lazy src=/images/2022-10-01-score_based_model/perturb_vp.gif alt></p><h3 id=reverse-sdes>Reverse SDEs<a hidden class=anchor aria-hidden=true href=#reverse-sdes>#</a></h3><p>The reverse SDEs for sample generation were proposed by B.D. Anderson in 1982, stating that every SDE has a corresponding reverse SDE equation, as follows:</p>$$
dx = [f(x,t) - g^2(t) \nabla_x \log p_t(x)]dt + g(t)d\bf{w}
$$<p>Here, \(dt\) is a negative infinitesimally small time step, and \(t\) is the process from \(T \rightarrow 0\). To solve the reverse SDE, we need to determine the score function \(\nabla_x \log p_t(x)\).</p><p><img loading=lazy src=../figures/2022-10-score_based_model/denoise_vp.gif alt="Reverse stochastic process dynamic diagram, i.e., the denoising process (source: Yang Song&amp;rsquo;s Blog 2021)" title="Reverse stochastic process dynamic diagram, i.e., the denoising process (source: Yang Song's Blog 2021)"></p><p>Similar to the NCSN loss function, we can still implement SDE-based score estimation based on the score model and score matching method, replacing the noise in the discrete process at the \(i\)th time with the noise at time \(t\), with the formula as follows:</p>$$
\mathcal{L}=\mathbb{E}_{t \in \mathcal{U}(0,T)} \mathbb{E}_{p_t(x)} [\lambda(t) \lVert \nabla_x \log p_t(x) - s_\theta(x,t) \rVert^2_2]
$$<p>Here, to ensure that the loss is of the same order at different \(t\) times, let \(\lambda(t) \propto 1/ \mathbb{E} \lVert \log p(x(t)|x(0)) \rVert^2_2\). After optimizing the score model \(s_\theta(x,t)\), substitute it into the reverse SDE:</p>$$
dx = [f(x,t) - g^2(t)s_\theta(x,t)]dt + g(t)d\bf{w}
$$<p><img loading=lazy src=/images/2022-10-01-score_based_model/sde_schematic.jpg alt></p><p>After calculating the specific expression of the reverse SDE, we need to consider how to solve the reverse SDE.</p><p>Solving the reverse SDE. We can use numerical methods to solve the reverse SDE, among which the simplest numerical method is the Euler-Maruyama method. This method describes the reverse SDE with finite time steps and infinitesimal Gaussian noise. Specifically, it initializes \(t=T\), \(\nabla_t \approx 0\) (negative time difference), and iterates the following process until \(t \approx 0\):</p>$$
\begin{align*}
\Delta x & \leftarrow [f(x,t) - g^2(t)s_\theta(x,t)] \Delta t + g(t) \sqrt{|\Delta t|}z_t \\
x & \leftarrow x + \Delta x \\
t & \leftarrow t + \Delta t
\end{align*}
$$<p>Of course, in addition to this, the author also mentioned other numerical methods, such as the Milstein method and the stochastic Runge-Kutta method. Since the author did not use these methods in the end, they are not elaborated here. Interested friends can study the corresponding papers.</p><p>The author proposed a method similar to the Euler-Maruyama method but more suitable for this reverse SDE, which is a method more suitable for this framework, called the predictor-corrector (PC) sampling method.</p><p>The PC sampling method can be viewed from two stages. The first stage is prediction, that is, to solve the \(x_i\) of the previous moment by any numerical method. However, due to the existence of errors at this time, the results are inaccurate, so the second stage of correction is needed to adjust the obtained results for \(M\) steps. This stage mainly uses the sampling method in the score model for correction, such as Langevin MCMC. As for the specific sampling formula, we will not discuss it for now, because our goal is not to use a specific SDE to represent SMLD or DDPM. Next, I will introduce how to unify the above two models with SDEs.</p><h3 id=sdes-unify-diffusion-models>SDEs Unify Diffusion Models<a hidden class=anchor aria-hidden=true href=#sdes-unify-diffusion-models>#</a></h3><p>For SMLD, by subtracting the noise addition formula at moments \( \sigma_i \) and \( \sigma_{i-1} \), we can obtain the following noise addition method:</p>$$
x_i = x_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2} z_{i-1}, \ z_{i-1} \sim \mathcal{N}(0,I)
$$<p>As the number of noise additions approaches infinity, we can derive:</p>$$
\begin{align*}
x(t + \Delta t) - x(t) &= \sqrt{\frac{d\sigma^2(t)}{dt}} \sqrt{\Delta t} z(t) \\
dx &= \sqrt{\frac{d\sigma^2(t)}{dt}} dw
\end{align*}
$$<p>For DDPM, the noise addition method is:</p>$$
x_i = \sqrt{1-\beta_i}x_{i-1} + \sqrt{\beta_i}z_{i-1}, \ z_{i-1} \sim \mathcal{N}(0, I)
$$<p>As the number of noise additions approaches infinity, we can derive:</p>$$
dx = -\frac{1}{2} \beta(t)xdt + \sqrt{\beta(t)}dw
$$<p>Since in the noise addition process, the noise in SMLD tends to infinity as \( t \rightarrow \infty \), its corresponding SDE is referred to as a Variance Exploding (VE) SDE. Conversely, the noise in DDPM tends to a boundary value as \( t \rightarrow \infty \), so its corresponding SDE is referred to as a Variance Preserving (VP) SDE.</p><p>After determining the SDE representations for SMLD and DDPM, let&rsquo;s revisit the specific expressions of the PC sampling in the two algorithms, as shown in <em>Algorithm 2, 3</em>.</p><p>The prediction phase can use any numerical method to solve the reverse SDE, while the correction phase uses the MCMC method based on the score model. In PC sampling, the predictor and corrector are used alternately. Specifically, the numerical method is used as the predictor, and the annealed Langevin dynamics sampling is used as the corrector.</p><p>From SDEs to ODEs. For an SDE, we can express the SDE in an equivalent form based on the Fokker-Planck equation:</p>$$
dx = [f(x,t)-\frac{1}{2}(g^2(t)-\sigma^2(t))\nabla_x \log p_t(x)]dt + \sigma(t)d\bf{w}
$$<p>The two SDE formulations are equivalent, hence they share the same marginal probability distribution \( p_t(x) \). If we set \( \sigma(t) = 0 \) in the SDE, we obtain an ordinary differential equation (ODE), commonly referred to as the Probability Flow ODE:</p>$$
dx = [f(x,t)-\frac{1}{2} g^2(t)\nabla_x \log p_t(x)]dt
$$<p>The figure below illustrates the noise addition and sampling processes of SDEs and Probability Flow ODEs. It can be seen that the trajectory of the Probability Flow ODE is smooth, while the trajectory of the SDE is stochastic, but they share the same marginal distribution. Some may wonder why the Probability Flow ODE is mentioned suddenly, of course, it is because it has advantages over SDEs. For example, ODEs are easier to solve than SDEs, thus faster in sampling; ODEs discard random noise throughout the process, making the process deterministic, allowing for the calculation of probability density. However, ODEs also have disadvantages, such as not generating as well as SDEs.</p><p><img loading=lazy src=/images/2022-10-01-score_based_model/teaser.jpg alt></p><p>Additionally, when \( \nabla_x \log p_t(x) \) is replaced by the approximated \( s_\theta(x,t) \), the Probability Flow ODE becomes a special case of a Neural ODE. At the same time, the Probability Flow ODE is also an example of a continuous Flow model because the Probability Flow ODE transforms the data distribution into the prior noise distribution, and the process is reversible. Therefore, the Probability Flow ODE inherits the characteristics of Neural ODEs or continuous Flow models, such as accurate likelihood calculation. We can use numerical ODEs to calculate unknown data distributions from the prior distribution.</p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p>[1] Yang Song, <a href=https://yang-song.net/blog/2021/score/>https://yang-song.net/blog/2021/score/</a>.</p><p>[2] Song, Y., & Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32.</p><p>[3] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://jiaxiangc.github.io/post/2024-05-01-progressive_step_distillation/><span class=title>« Prev</span><br><span>Progressive Step Distillation</span>
</a><a class=next href=https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/><span class=title>Next »</span><br><span>Denoise Diffusion Probability Model</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on x" href="https://x.com/intent/tweet/?text=Score-based%20Generative%20Model&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f&amp;title=Score-based%20Generative%20Model&amp;summary=Score-based%20Generative%20Model&amp;source=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f&title=Score-based%20Generative%20Model"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on whatsapp" href="https://api.whatsapp.com/send?text=Score-based%20Generative%20Model%20-%20https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on telegram" href="https://telegram.me/share/url?text=Score-based%20Generative%20Model&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Score-based Generative Model on ycombinator" href="https://news.ycombinator.com/submitlink?t=Score-based%20Generative%20Model&u=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-10-01-score_based_model%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://jiaxiangc.github.io/>Jiaxiang's Blogs</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>