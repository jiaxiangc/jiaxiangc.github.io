<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Denoise Diffusion Probability Model | Jiaxiang's Blogs</title>
<meta name=keywords content><meta name=description content="Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM."><meta name=author content="Me"><link rel=canonical href=https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Denoise Diffusion Probability Model"><meta property="og:description" content="Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM."><meta property="og:type" content="article"><meta property="og:url" content="https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/"><meta property="og:image" content="https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-09-15T11:30:03+00:00"><meta property="article:modified_time" content="2022-09-15T11:30:03+00:00"><meta property="og:site_name" content="Homepage Test"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Denoise Diffusion Probability Model"><meta name=twitter:description content="Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://jiaxiangc.github.io/post/"},{"@type":"ListItem","position":2,"name":"Denoise Diffusion Probability Model","item":"https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Denoise Diffusion Probability Model","name":"Denoise Diffusion Probability Model","description":"Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM.","keywords":[],"articleBody":" Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM.\nDDPMs The core modeling process of the DDPM consists of a forward diffusion process and a reverse denoising process, both of which are constructed on a Markov chain, as depicted in Figure 1. During the forward diffusion phase, minute Gaussian noise is iteratively added to the image over continuous time steps. As the time steps approach infinity, the distribution of the image gradually converges to a standard Gaussian distribution. The objective of the reverse denoising phase is to learn how to remove this noise incrementally in the reverse time steps until the time step reaches zero, at which point the distribution of the image reverts to that of the original image. Ideally, an excellent diffusion model can start from any Gaussian noise state and, through multiple steps of denoising iterations, produce high-quality images that conform to the distribution of the training dataset.\nFigure 1: An Overview of the DDPM Framework\nForward Process The forward process of DDPM begins by sampling a data point \\( x_0 \\sim q_{\\text{data}} \\) from the true data distribution. As the continuous time \\( t \\) progresses, a faint Gaussian noise is gradually added to the data \\( x_0 \\), with its standard deviation and variance determined by \\( \\beta_t \\). Specifically, the forward process generates a series of images \\( x_1, \\ldots, x_T \\) with noise continuously injected. When \\( T \\) approaches infinity, \\( x_T \\) can be considered as belonging to an independent Gaussian distribution \\( \\mathcal{N}(0, \\mathbf{I}) \\). The mathematical definition of the forward process is as follows:\n$$ q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t I) $$ Since the forward process of DDPM is built on a Markov chain, we can define the joint probability distribution of the entire process as:\n$$ q(x_{1:T} | x_0) = \\prod_{t=1}^{T} q(x_t | x_{t-1}) $$ Using the reparameterization trick and the properties of the Markov chain, we can derive:\n$$ x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} z $$ Furthermore, through reparameterization, we can obtain the marginal probability distribution of the noisy data:\n$$ q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) I) $$ This marginal probability distribution is the key target of the DDPM forward process modeling. That is to say, given any \\( x_0 \\sim q_{\\text{data}} \\), we can obtain the noisy data \\( x_t \\). However, the main goal of DDPM is to learn to generate images. Next, we will introduce how to derive the image generation objective function of the model based on the forward process, that is, the reverse process.\nReverse Process Before engaging in the reverse process inference, let us first clarify the objective of this process. If we intend to fit the reverse process with a model network, it is imperative to deduce the formula of the reverse process, which must encompass the unknown variables that the model seeks to derive. Why is this the case? If we already knew the specific formula and every variable within \\( q(x_{t-1}|x_t) \\), there would be no need for fitting.\nUpon examining the formula for the reverse process, it is evident that we require the distribution outcomes for \\( x_t \\) and \\( x_{t-1} \\). Since \\( x_0 \\) does not influence \\( x_t \\) and \\( x_{t-1} \\), it follows that \\( q(x_{t-1}|x_t) = q(x_{t-1}|x_t,x_0) \\). By integrating Bayesâ€™ theorem with the marginal probability distribution \\( q(x_t|x_0) \\), we can establish the following:\n$$ \\begin{align*} q(x_{t-1}|x_t,x_0) \u0026= q(x_t|x_{t-1},x_0) \\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\\\ \u0026 \\propto exp(\\frac{1}{2}(\\frac{x_t-\\sqrt{\\alpha_t}x_{t-1}}{\\beta_t}+\\frac{(x_{t-1}-\\sqrt{\\bar{\\alpha}_{t-1}}x_0)^2}{1-\\bar{\\alpha}_{t-1}}-\\frac{(x_t-\\sqrt{\\bar{\\alpha}_t}x_0)^2}{1-\\bar{\\alpha_t}})) \\\\ \u0026= exp(-\\frac{1}{2} ((\\frac{\\alpha_t}{\\beta_t}+\\frac{1}{1-\\bar{\\alpha}_{t-1}})x_{t-1}^2-(\\frac{2\\sqrt{\\alpha_t}}{\\beta_t}+\\frac{2\\sqrt{\\bar{\\alpha}_t}}{1-\\bar{\\alpha}_{t-1}}x_0)x_{t-1}+C(x_t,x_0))) \\end{align*} $$ Where \\( C(x_t, x_0) \\) is an expression independent of \\( x_{t-1} \\), we can deduce the coefficients of the quadratic equation as follows:\n$$ \\tilde{\\beta}_t = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t} \\cdot \\beta_t \\\\ \\tilde{\\mu}_t (x_t,x_0) = \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_{t} + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar{\\alpha}_t}x_0 $$ In the process of constructing mathematical models, we often face choices: when substituting the variable \\( x_0 \\), we obtain the mean expression \\( \\tilde{\\mu}_t = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}} z_t \\right) \\). Which one should we actually use? In fact, we need to consider both. During the training phase, since \\( x_0 \\) is known, we naturally tend to use the first expression. In the generation phase, \\( x_0 \\) is unknown, making the second expression particularly important. They are not mutually exclusive but show different applicability depending on the application scenario. The choice depends on whether our dataset is already clear.\nHaving derived the formula for the reverse diffusion process, we now need to fit the distribution derived from \\( q(x_{t-1}|x_t,x_0) \\) with the conditional probability \\( p_\\theta(x_{t-1}|x_t) \\). So, how do we fit to construct the loss function? Obviously, this is a likelihood-based model problem. The loss function is derived by constructing a variational lower bound. There are mainly two derivation methods: one is to construct the Kullback-Leibler (KL) divergence based on the logarithmic likelihood \\( \\log p(x_0) \\); the other is to use Jensenâ€™s inequality for derivation. The following will show the derivation process of the second method, namely the calculation formula for \\( L_{\\text{VLB}} \\) as follows:\n$$ \\begin{align*} L_{CE} \u0026= -\\mathbb{E}_{q(x_0)} \\log p_\\theta(x_0) \\\\ \u0026= -\\mathbb{E}_{q(x_0)} \\log \\left( \\int p_\\theta(x_{0:T}) dx_{1:T} \\right) \\\\ \u0026= -\\mathbb{E}_{q(x_0)} \\log \\left( \\mathbb{E}_{q(x_{1:T}|x_0)} \\frac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\right) \\\\ \u0026 \\le -\\mathbb{E}_{q(x_{0:T})} \\log \\frac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\\\ \u0026= \\mathbb{E}_q(x_{0:T})\\left[ \\log \\frac{q(x_{1:T}|x_0)}{p_\\theta(x_{0:T})} \\right] = L_{\\text{VLB}} \\end{align*} $$ Expanding \\(L_{\\text{VLB}}\\), the derivation process is illustrated as follows:\n$$ \\begin{array}{l}L_{\\mathrm{VLB}}=\\mathbb{E}_{q\\left(\\mathbf{x}_{0: T}\\right)}\\left[\\log \\frac{q\\left(\\mathbf{x}_{1: T} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{0: T}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[\\log \\frac{\\prod_{t=1}^{T} q\\left(\\mathbf{x}_{t} \\mid \\mathbf{x}_{t-1}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{T}\\right) \\prod_{t=1}^{T} p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[-\\log p_{\\theta}\\left(\\mathbf{x}_{T}\\right)+\\sum_{t=1}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t} \\mid \\mathbf{x}_{t-1}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[-\\log p_{\\theta}\\left(\\mathbf{x}_{T}\\right)+\\sum_{t=2}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t} \\mid \\mathbf{x}_{t-1}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}+\\log \\frac{q\\left(\\mathbf{x}_{1} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[-\\log p_{\\theta}\\left(\\mathbf{x}_{T}\\right)+\\sum_{t=2}^{T} \\log \\left(\\frac{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}, \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)} \\cdot \\frac{q\\left(\\mathbf{x}_{t} \\mid \\mathbf{x}_{0}\\right)}{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{0}\\right)}\\right)+\\log \\frac{q\\left(\\mathbf{x}_{1} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[-\\log p_{\\theta}\\left(\\mathbf{x}_{T}\\right)+\\sum_{t=2}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}, \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}+\\sum_{t=2}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t} \\mid \\mathbf{x}_{0}\\right)}{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{0}\\right)}+\\log \\frac{q\\left(\\mathbf{x}_{1} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[-\\log p_{\\theta}\\left(\\mathbf{x}_{T}\\right)+\\sum_{t=2}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}, \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}+\\log \\frac{q\\left(\\mathbf{x}_{T} \\mid \\mathbf{x}_{0}\\right)}{q\\left(\\mathbf{x}_{1} \\mid \\mathbf{x}_{0}\\right)}+\\log \\frac{q\\left(\\mathbf{x}_{1} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)}\\right] \\\\ =\\mathbb{E}_{q}\\left[\\log \\frac{q\\left(\\mathbf{x}_{T} \\mid \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{T}\\right)}+\\sum_{t=2}^{T} \\log \\frac{q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}, \\mathbf{x}_{0}\\right)}{p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)}-\\log p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)\\right] \\\\ =\\mathbb{E}_{q}[\\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_{T} \\mid \\mathbf{x}_{0}\\right) \\| p_{\\theta}\\left(\\mathbf{x}_{T}\\right)\\right)}_{L_{T}}+\\sum_{t=2}^{T} \\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}, \\mathbf{x}_{0}\\right) \\| p_{\\theta}\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_{t}\\right)\\right)-\\log p_{\\theta}\\left(\\mathbf{x}_{0} \\mid \\mathbf{x}_{1}\\right)}_{L_{t-1}}] \\\\\\end{array} $$ When delving deeper into the construction of the loss function for the reverse diffusion process, we note that \\( L_{t-1} \\) is a key component of \\( L_{\\text{VLB}} \\), which relies on the dynamic changes of variables, while \\( L_{T} \\), as a constant term, can be disregarded in calculations. Next, letâ€™s expand \\( L_{t} \\), the transition from \\( t-1 \\) to \\( t \\), with the following expression:\n$$ L_{t-1} = \\mathbb{E}_q\\left[\\frac{1}{2\\sigma_t^2} \\left\\| \\tilde{\\mu}_t(x_t,x_0) - \\mu_\\theta(x_t,t) \\right\\|^2 \\right] + C $$ This formula is primarily constructed based on the objective of mean modeling. However, in addition to the mean, we can also target the noise or the original image itself for modeling. By further substituting \\( \\mu \\) and simplifying, we obtain a simplified loss function:\n$$ \\begin{align*} L_{\\text{simple}}(\\theta) \u0026= \\mathbb{E}_q\\left[\\left\\| \\epsilon - \\epsilon_\\theta(x_t,t) \\right\\|^2 \\right] \\\\ \u0026= \\mathbb{E}_q\\left[\\left\\| \\epsilon - \\epsilon_\\theta\\left(\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon, t\\right) \\right\\|^2 \\right] \\end{align*} $$ The above introduces the mathematical reasoning part of DDPM. Although the mathematical reasoning process of DDPM may seem complex, we ultimately arrive at a concise and clear loss function, which provides a solid foundation for training diffusion models.\nTraining and Sample Process The objective function of DDPM is a simple Gaussian noise mean square error prediction. However, due to the concept of time step \\( t \\) in the mathematical definition of DDPM, its training process needs to consider the prediction of Gaussian noise at each time step, and the same applies to the sampling process. The specific details are shown in the figure below.\nFigure 2: The training and sampling algorithm of DDPM\nDDIM Accelerate Generation Process The reverse diffusion process of DDIM significantly differs from that of DDPM. Unlike the step-by-step retrogression of DDPM from step \\( t \\) to \\( t-1 \\), DDIM first reverts from step \\( t \\) back to the initial state \\( x_0 \\), and then predicts \\( x_{t-1} \\) based on \\( x_t \\) and \\( x_0 \\). Itâ€™s worth noting that although DDPM could theoretically perform an operation that jumps to \\( x_0 \\), the original paper did not adopt this method. In DDIM, the predicted \\( x_0 \\) is referred to as the denoised observation, and its mathematical expression is defined as follows:\n$$ f_\\theta^{(t)}(x_t) := \\frac{x_t - \\sqrt{1 - \\alpha_t} \\cdot \\epsilon_\\theta^{(t)}}{\\sqrt{\\alpha_t}} $$ Given a fixed prior \\( p_\\theta(x_T) = \\mathcal{N}(0, I) \\), we can determine the objective for the neural network to approximate the reverse diffusion process, with the expression given by:\n$$ p_\\theta^{(t)}(x_{t-1} | x_t) = \\begin{cases} \\mathcal{N}(f_\\theta^{(1)}(x_1), \\sigma_1^2 I), \u0026 \\text{if } t = 1 \\\\ q_\\sigma(x_{t-1} | x_t, f_\\theta^{(t)}(x_t)), \u0026 \\text{otherwise} \\end{cases} $$ After establishing the target for the neural network approximation, we further explore the results of the sampled \\( x_{t-1} \\). Reviewing the diffusion processâ€™s \\( q(x_{t-1} | x_0) \\), we have proven that this distribution follows a normal distribution, thus allowing the use of the reparameterization trick for expression:\n$$ x_{t-1} = \\sqrt{\\alpha_{t-1}} x_0 + \\sqrt{1 - \\alpha_{t-1}} \\epsilon_\\theta^{(t)}(x_t) $$ According to the properties of the Gaussian distribution, i.e., \\( x + y \\sim \\mathcal{N}(0, \\sqrt{a^2 + b^2}) \\), we can split the second term in the above equation:\n$$ x_{t-1} = \\sqrt{\\alpha_{t-1}} x_0 + \\sqrt{1 - \\alpha_{t-1} - \\sigma_t^2} \\epsilon_\\theta^{(t)}(x_t) + \\sigma_t \\epsilon_t $$ Here, \\( \\epsilon_\\theta^{(t)}(x_t) \\) and \\( \\epsilon_t \\) are both random variables from a Gaussian distribution. Further substituting the expression for \\( x_0 \\) :\n$$ x_0 = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\sqrt{1 - \\alpha_t} \\epsilon_\\theta^{(t)}(x_t) \\right) $$ After substituting \\( x_0 \\), we obtain:\n$$ x_{t-1} = \\sqrt{\\alpha_{t-1}} \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\sqrt{1 - \\alpha_t} \\epsilon_\\theta^{(t)}(x_t) \\right) + \\sqrt{1 - \\alpha_{t-1} - \\sigma_t^2} \\epsilon_\\theta^{(t)}(x_t) + \\sigma_t \\epsilon_t $$ Specifically, in DDPM, \\( x_{t-1} \\) is obtained through the reparameterization of \\( p_\\theta(x_{t-1} | x_t) \\), while in DDIM, \\( x_{t-1} \\) is derived based on the diffusion process. This actually verifies the correctness of the authorâ€™s proposed \\( q_\\sigma(x_{t-1} | x_t, x_0) \\).\nSample Process without Intermediate Noise Although DDIM is not based on a Markov chain, its training process is consistent with that of DDPM. That is, the DDPM model can be used for accelerated inference without retraining, reducing from 1000 steps to 50. Specifically, the sampling formula for DDIM can be defined as:\n$$ q_{\\sigma}\\left(\\boldsymbol{x}_{\\tau_{i-1}} \\mid \\boldsymbol{x}_{\\tau_i}, \\boldsymbol{x}_{0}\\right)=\\mathcal{N}\\left(\\sqrt{\\alpha_{\\tau_{i-1}}} \\boldsymbol{x}_{0}+\\sqrt{1-\\alpha_{\\tau_{i-1}}-\\sigma_{\\tau_i}^{2}} \\cdot \\frac{\\boldsymbol{x}_{\\tau_i}-\\sqrt{\\alpha_{\\tau_i}} \\boldsymbol{x}_{0}}{\\sqrt{1-\\alpha_{\\tau_i}}}, \\sigma_{\\tau_i}^{2} \\boldsymbol{I}\\right) $$ In the sampling process of DDIM, it is common to set \\( \\sigma = 0 \\). As shown in the figure, the sampling time steps of DDIM are not continuous; it uses \\( x_0 \\) as a stepping stone and can jump from \\( x_3 \\) to \\( x_1 \\).\nReference [1]Ho, J., Jain, A., \u0026 Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems, 33, 6840-6851.\n[2]Song, J., Meng, C., \u0026 Ermon, S. (2020). Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502.\n","wordCount":"1901","inLanguage":"en","image":"https://jiaxiangc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-09-15T11:30:03Z","dateModified":"2022-09-15T11:30:03Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaxiangc.github.io/post/2022-09-01-denoise_diffusion_model/"},"publisher":{"@type":"Organization","name":"Jiaxiang's Blogs","logo":{"@type":"ImageObject","url":"https://jiaxiangc.github.io/%3Clink%20/%20abs%20url%3E"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"]]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jiaxiangc.github.io/ accesskey=h title="Jiaxiang's Blogs (Alt + H)"><img src=https://jiaxiangc.github.io/apple-touch-icon.png alt aria-label=logo height=35>Jiaxiang's Blogs</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://jiaxiangc.github.io/post/ title=POSTS><span>POSTS</span></a></li><li><a href=https://jiaxiangc.github.io/tags/ title=TAGS><span>TAGS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jiaxiangc.github.io/>Home</a>&nbsp;Â»&nbsp;<a href=https://jiaxiangc.github.io/post/>Posts</a></div><h1 class="post-title entry-hint-parent">Denoise Diffusion Probability Model</h1><div class=post-meta><span title='2022-09-15 11:30:03 +0000 +0000'>September 15, 2022</span>&nbsp;Â·&nbsp;9 min&nbsp;Â·&nbsp;1901 words&nbsp;Â·&nbsp;Me</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ol><li><a href=#ddpms>DDPMs</a><ol><li><a href=#forward-process>Forward Process</a></li><li><a href=#reverse-process>Reverse Process</a></li><li><a href=#training-and-sample-process>Training and Sample Process</a></li></ol></li><li><a href=#ddim>DDIM</a><ol><li><a href=#accelerate-generation-process>Accelerate Generation Process</a></li><li><a href=#sample-process-without-intermediate-noise>Sample Process without Intermediate Noise</a></li></ol></li><li><a href=#reference>Reference</a></li></ol></nav></div></details></div><div class=post-content><p>Diffusion Models (DM) have achieved remarkable progress in the realms of image, video, and audio processing. This paper delves into the foundational work of the diffusion models, namely the Denoise Diffusion Probability Model (DDPM), and further introduces the widely used rapid sampling technique within diffusion models, the Denoise Diffusion Implicit Model (DDIM). The focus of this paper is on the modeling principles, training processes, and inference methods of DDPM and DDIM.</p><h2 id=ddpms>DDPMs<a hidden class=anchor aria-hidden=true href=#ddpms>#</a></h2><p>The core modeling process of the DDPM consists of a forward diffusion process and a reverse denoising process, both of which are constructed on a Markov chain, as depicted in Figure 1. During the forward diffusion phase, minute Gaussian noise is iteratively added to the image over continuous time steps. As the time steps approach infinity, the distribution of the image gradually converges to a standard Gaussian distribution. The objective of the reverse denoising phase is to learn how to remove this noise incrementally in the reverse time steps until the time step reaches zero, at which point the distribution of the image reverts to that of the original image. Ideally, an excellent diffusion model can start from any Gaussian noise state and, through multiple steps of denoising iterations, produce high-quality images that conform to the distribution of the training dataset.</p><p><img loading=lazy src=/images/2022-09-01-denoise_diffusion_model/ddpm_overview.png alt>
Figure 1: An Overview of the DDPM Framework</p><h3 id=forward-process>Forward Process<a hidden class=anchor aria-hidden=true href=#forward-process>#</a></h3><p>The forward process of DDPM begins by sampling a data point \( x_0 \sim q_{\text{data}} \) from the true data distribution. As the continuous time \( t \) progresses, a faint Gaussian noise is gradually added to the data \( x_0 \), with its standard deviation and variance determined by \( \beta_t \). Specifically, the forward process generates a series of images \( x_1, \ldots, x_T \) with noise continuously injected. When \( T \) approaches infinity, \( x_T \) can be considered as belonging to an independent Gaussian distribution \( \mathcal{N}(0, \mathbf{I}) \). The mathematical definition of the forward process is as follows:</p>$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$<p>Since the forward process of DDPM is built on a Markov chain, we can define the joint probability distribution of the entire process as:</p>$$
q(x_{1:T} | x_0) = \prod_{t=1}^{T} q(x_t | x_{t-1})
$$<p>Using the reparameterization trick and the properties of the Markov chain, we can derive:</p>$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} z
$$<p>Furthermore, through reparameterization, we can obtain the marginal probability distribution of the noisy data:</p>$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
$$<p>This marginal probability distribution is the key target of the DDPM forward process modeling. That is to say, given any \( x_0 \sim q_{\text{data}} \), we can obtain the noisy data \( x_t \). However, the main goal of DDPM is to learn to generate images. Next, we will introduce how to derive the image generation objective function of the model based on the forward process, that is, the reverse process.</p><h3 id=reverse-process>Reverse Process<a hidden class=anchor aria-hidden=true href=#reverse-process>#</a></h3><p>Before engaging in the reverse process inference, let us first clarify the objective of this process. If we intend to fit the reverse process with a model network, it is imperative to deduce the formula of the reverse process, which must encompass the unknown variables that the model seeks to derive. Why is this the case? If we already knew the specific formula and every variable within \( q(x_{t-1}|x_t) \), there would be no need for fitting.</p><p>Upon examining the formula for the reverse process, it is evident that we require the distribution outcomes for \( x_t \) and \( x_{t-1} \). Since \( x_0 \) does not influence \( x_t \) and \( x_{t-1} \), it follows that \( q(x_{t-1}|x_t) = q(x_{t-1}|x_t,x_0) \). By integrating Bayes&rsquo; theorem with the marginal probability distribution \( q(x_t|x_0) \), we can establish the following:</p>$$
\begin{align*}
q(x_{t-1}|x_t,x_0) &= q(x_t|x_{t-1},x_0) \frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\
& \propto exp(\frac{1}{2}(\frac{x_t-\sqrt{\alpha_t}x_{t-1}}{\beta_t}+\frac{(x_{t-1}-\sqrt{\bar{\alpha}_{t-1}}x_0)^2}{1-\bar{\alpha}_{t-1}}-\frac{(x_t-\sqrt{\bar{\alpha}_t}x_0)^2}{1-\bar{\alpha_t}})) \\
&= exp(-\frac{1}{2} ((\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}})x_{t-1}^2-(\frac{2\sqrt{\alpha_t}}{\beta_t}+\frac{2\sqrt{\bar{\alpha}_t}}{1-\bar{\alpha}_{t-1}}x_0)x_{t-1}+C(x_t,x_0)))
\end{align*}
$$<p>Where \( C(x_t, x_0) \) is an expression independent of \( x_{t-1} \), we can deduce the coefficients of the quadratic equation as follows:</p>$$
\tilde{\beta}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \cdot \beta_t \\
\tilde{\mu}_t (x_t,x_0) = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0
$$<p>In the process of constructing mathematical models, we often face choices: when substituting the variable \( x_0 \), we obtain the mean expression \( \tilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} z_t \right) \). Which one should we actually use? In fact, we need to consider both. During the training phase, since \( x_0 \) is known, we naturally tend to use the first expression. In the generation phase, \( x_0 \) is unknown, making the second expression particularly important. They are not mutually exclusive but show different applicability depending on the application scenario. The choice depends on whether our dataset is already clear.</p><p>Having derived the formula for the reverse diffusion process, we now need to fit the distribution derived from \( q(x_{t-1}|x_t,x_0) \) with the conditional probability \( p_\theta(x_{t-1}|x_t) \). So, how do we fit to construct the loss function? Obviously, this is a likelihood-based model problem. The loss function is derived by constructing a variational lower bound. There are mainly two derivation methods: one is to construct the Kullback-Leibler (KL) divergence based on the logarithmic likelihood \( \log p(x_0) \); the other is to use Jensen&rsquo;s inequality for derivation. The following will show the derivation process of the second method, namely the calculation formula for \( L_{\text{VLB}} \) as follows:</p>$$
\begin{align*}
L_{CE} &= -\mathbb{E}_{q(x_0)} \log p_\theta(x_0) \\
&= -\mathbb{E}_{q(x_0)} \log \left( \int p_\theta(x_{0:T}) dx_{1:T} \right) \\
&= -\mathbb{E}_{q(x_0)} \log \left( \mathbb{E}_{q(x_{1:T}|x_0)} \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right) \\
& \le -\mathbb{E}_{q(x_{0:T})} \log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\
&= \mathbb{E}_q(x_{0:T})\left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right] = L_{\text{VLB}}
\end{align*}
$$<p>Expanding \(L_{\text{VLB}}\), the derivation process is illustrated as follows:</p>$$
\begin{array}{l}L_{\mathrm{VLB}}=\mathbb{E}_{q\left(\mathbf{x}_{0: T}\right)}\left[\log \frac{q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{0: T}\right)}\right] \\ =\mathbb{E}_{q}\left[\log \frac{\prod_{t=1}^{T} q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}\right)}{p_{\theta}\left(\mathbf{x}_{T}\right) \prod_{t=1}^{T} p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}\right] \\ =\mathbb{E}_{q}\left[-\log p_{\theta}\left(\mathbf{x}_{T}\right)+\sum_{t=1}^{T} \log \frac{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}\right] \\ =\mathbb{E}_{q}\left[-\log p_{\theta}\left(\mathbf{x}_{T}\right)+\sum_{t=2}^{T} \log \frac{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}+\log \frac{q\left(\mathbf{x}_{1} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)}\right] \\ =\mathbb{E}_{q}\left[-\log p_{\theta}\left(\mathbf{x}_{T}\right)+\sum_{t=2}^{T} \log \left(\frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)} \cdot \frac{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{0}\right)}{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{0}\right)}\right)+\log \frac{q\left(\mathbf{x}_{1} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)}\right] \\ =\mathbb{E}_{q}\left[-\log p_{\theta}\left(\mathbf{x}_{T}\right)+\sum_{t=2}^{T} \log \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}+\sum_{t=2}^{T} \log \frac{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{0}\right)}{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{0}\right)}+\log \frac{q\left(\mathbf{x}_{1} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)}\right] \\ =\mathbb{E}_{q}\left[-\log p_{\theta}\left(\mathbf{x}_{T}\right)+\sum_{t=2}^{T} \log \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}+\log \frac{q\left(\mathbf{x}_{T} \mid \mathbf{x}_{0}\right)}{q\left(\mathbf{x}_{1} \mid \mathbf{x}_{0}\right)}+\log \frac{q\left(\mathbf{x}_{1} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)}\right] \\ =\mathbb{E}_{q}\left[\log \frac{q\left(\mathbf{x}_{T} \mid \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{T}\right)}+\sum_{t=2}^{T} \log \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right)}{p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)}-\log p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)\right] \\ =\mathbb{E}_{q}[\underbrace{D_{\mathrm{KL}}\left(q\left(\mathbf{x}_{T} \mid \mathbf{x}_{0}\right) \| p_{\theta}\left(\mathbf{x}_{T}\right)\right)}_{L_{T}}+\sum_{t=2}^{T} \underbrace{D_{\mathrm{KL}}\left(q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right) \| p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)\right)-\log p_{\theta}\left(\mathbf{x}_{0} \mid \mathbf{x}_{1}\right)}_{L_{t-1}}] \\\end{array}
$$<p>When delving deeper into the construction of the loss function for the reverse diffusion process, we note that \( L_{t-1} \) is a key component of \( L_{\text{VLB}} \), which relies on the dynamic changes of variables, while \( L_{T} \), as a constant term, can be disregarded in calculations. Next, let&rsquo;s expand \( L_{t} \), the transition from \( t-1 \) to \( t \), with the following expression:</p>$$
L_{t-1} = \mathbb{E}_q\left[\frac{1}{2\sigma_t^2} \left\| \tilde{\mu}_t(x_t,x_0) - \mu_\theta(x_t,t) \right\|^2 \right] + C
$$<p>This formula is primarily constructed based on the objective of mean modeling. However, in addition to the mean, we can also target the noise or the original image itself for modeling. By further substituting \( \mu \) and simplifying, we obtain a simplified loss function:</p>$$
\begin{align*}
L_{\text{simple}}(\theta) &= \mathbb{E}_q\left[\left\| \epsilon - \epsilon_\theta(x_t,t) \right\|^2 \right] \\
&= \mathbb{E}_q\left[\left\| \epsilon - \epsilon_\theta\left(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t\right) \right\|^2 \right]
\end{align*}
$$<p>The above introduces the mathematical reasoning part of DDPM. Although the mathematical reasoning process of DDPM may seem complex, we ultimately arrive at a concise and clear loss function, which provides a solid foundation for training diffusion models.</p><h3 id=training-and-sample-process>Training and Sample Process<a hidden class=anchor aria-hidden=true href=#training-and-sample-process>#</a></h3><p>The objective function of DDPM is a simple Gaussian noise mean square error prediction. However, due to the concept of time step \( t \) in the mathematical definition of DDPM, its training process needs to consider the prediction of Gaussian noise at each time step, and the same applies to the sampling process. The specific details are shown in the figure below.</p><p><img loading=lazy src=/images/2022-09-01-denoise_diffusion_model/ddpm_algorithm.png alt>
Figure 2: The training and sampling algorithm of DDPM</p><h2 id=ddim>DDIM<a hidden class=anchor aria-hidden=true href=#ddim>#</a></h2><h3 id=accelerate-generation-process>Accelerate Generation Process<a hidden class=anchor aria-hidden=true href=#accelerate-generation-process>#</a></h3><p>The reverse diffusion process of DDIM significantly differs from that of DDPM. Unlike the step-by-step retrogression of DDPM from step \( t \) to \( t-1 \), DDIM first reverts from step \( t \) back to the initial state \( x_0 \), and then predicts \( x_{t-1} \) based on \( x_t \) and \( x_0 \). It&rsquo;s worth noting that although DDPM could theoretically perform an operation that jumps to \( x_0 \), the original paper did not adopt this method. In DDIM, the predicted \( x_0 \) is referred to as the denoised observation, and its mathematical expression is defined as follows:</p>$$
f_\theta^{(t)}(x_t) := \frac{x_t - \sqrt{1 - \alpha_t} \cdot \epsilon_\theta^{(t)}}{\sqrt{\alpha_t}}
$$<p>Given a fixed prior \( p_\theta(x_T) = \mathcal{N}(0, I) \), we can determine the objective for the neural network to approximate the reverse diffusion process, with the expression given by:</p>$$
p_\theta^{(t)}(x_{t-1} | x_t) = \begin{cases}
\mathcal{N}(f_\theta^{(1)}(x_1), \sigma_1^2 I), & \text{if } t = 1 \\
q_\sigma(x_{t-1} | x_t, f_\theta^{(t)}(x_t)), & \text{otherwise}
\end{cases}
$$<p>After establishing the target for the neural network approximation, we further explore the results of the sampled \( x_{t-1} \). Reviewing the diffusion process&rsquo;s \( q(x_{t-1} | x_0) \), we have proven that this distribution follows a normal distribution, thus allowing the use of the reparameterization trick for expression:</p>$$
x_{t-1} = \sqrt{\alpha_{t-1}} x_0 + \sqrt{1 - \alpha_{t-1}} \epsilon_\theta^{(t)}(x_t)
$$<p>According to the properties of the Gaussian distribution, i.e., \( x + y \sim \mathcal{N}(0, \sqrt{a^2 + b^2}) \), we can split the second term in the above equation:</p>$$
x_{t-1} = \sqrt{\alpha_{t-1}} x_0 + \sqrt{1 - \alpha_{t-1} - \sigma_t^2} \epsilon_\theta^{(t)}(x_t) + \sigma_t \epsilon_t
$$<p>Here, \( \epsilon_\theta^{(t)}(x_t) \) and \( \epsilon_t \) are both random variables from a Gaussian distribution. Further substituting the expression for \( x_0 \) :</p>$$
x_0 = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \sqrt{1 - \alpha_t} \epsilon_\theta^{(t)}(x_t) \right)
$$<p>After substituting \( x_0 \), we obtain:</p>$$
x_{t-1} = \sqrt{\alpha_{t-1}} \frac{1}{\sqrt{\alpha_t}} \left( x_t - \sqrt{1 - \alpha_t} \epsilon_\theta^{(t)}(x_t) \right) + \sqrt{1 - \alpha_{t-1} - \sigma_t^2} \epsilon_\theta^{(t)}(x_t) + \sigma_t \epsilon_t
$$<p>Specifically, in DDPM, \( x_{t-1} \) is obtained through the reparameterization of \( p_\theta(x_{t-1} | x_t) \), while in DDIM, \( x_{t-1} \) is derived based on the diffusion process. This actually verifies the correctness of the author&rsquo;s proposed \( q_\sigma(x_{t-1} | x_t, x_0) \).</p><h3 id=sample-process-without-intermediate-noise>Sample Process without Intermediate Noise<a hidden class=anchor aria-hidden=true href=#sample-process-without-intermediate-noise>#</a></h3><p>Although DDIM is not based on a Markov chain, its training process is consistent with that of DDPM. That is, the DDPM model can be used for accelerated inference without retraining, reducing from 1000 steps to 50. Specifically, the sampling formula for DDIM can be defined as:</p>$$
q_{\sigma}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}, \boldsymbol{x}_{0}\right)=\mathcal{N}\left(\sqrt{\alpha_{\tau_{i-1}}} \boldsymbol{x}_{0}+\sqrt{1-\alpha_{\tau_{i-1}}-\sigma_{\tau_i}^{2}} \cdot \frac{\boldsymbol{x}_{\tau_i}-\sqrt{\alpha_{\tau_i}} \boldsymbol{x}_{0}}{\sqrt{1-\alpha_{\tau_i}}}, \sigma_{\tau_i}^{2} \boldsymbol{I}\right)
$$<p>In the sampling process of DDIM, it is common to set \( \sigma = 0 \). As shown in the figure, the sampling time steps of DDIM are not continuous; it uses \( x_0 \) as a stepping stone and can jump from \( x_3 \) to \( x_1 \).</p><p><img loading=lazy src=/images/2022-09-01-denoise_diffusion_model/ddim_accelerate.png alt></p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p>[1]Ho, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems, 33, 6840-6851.</p><p>[2]Song, J., Meng, C., & Ermon, S. (2020). Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://jiaxiangc.github.io/post/2022-10-01-score_based_model/><span class=title>Â« Prev</span><br><span>Score-based Generative Model</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on x" href="https://x.com/intent/tweet/?text=Denoise%20Diffusion%20Probability%20Model&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f&amp;title=Denoise%20Diffusion%20Probability%20Model&amp;summary=Denoise%20Diffusion%20Probability%20Model&amp;source=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f&title=Denoise%20Diffusion%20Probability%20Model"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on whatsapp" href="https://api.whatsapp.com/send?text=Denoise%20Diffusion%20Probability%20Model%20-%20https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on telegram" href="https://telegram.me/share/url?text=Denoise%20Diffusion%20Probability%20Model&amp;url=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Denoise Diffusion Probability Model on ycombinator" href="https://news.ycombinator.com/submitlink?t=Denoise%20Diffusion%20Probability%20Model&u=https%3a%2f%2fjiaxiangc.github.io%2fpost%2f2022-09-01-denoise_diffusion_model%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://jiaxiangc.github.io/>Jiaxiang's Blogs</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>